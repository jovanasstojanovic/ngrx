import { CommonModule } from '@angular/common';
import * as i0 from '@angular/core';
import { Directive, Input, HostBinding, HostListener, Injectable, EventEmitter, InjectionToken, Inject, Output, NgModule } from '@angular/core';
import { BehaviorSubject, Subject, fromEvent, merge } from 'rxjs';
import { take } from 'rxjs/operators';

/**
 * Send a toggle audio request to a specific peer connection.
 */
class ToggleAudioUserDirective {
    constructor() {
        this.ngxWebrtcToggleAudioUser = null;
        this.isDisabled = true;
        this.isEnabled = false;
    }
    onClick() {
        this.toggleUserAudio();
    }
    toggleUserAudio() {
        if (!this.ngxWebrtcToggleAudioUser) {
            console.warn('user not set');
            return;
        }
        if (this.ngxWebrtcToggleAudioUser?.connection) {
            this.ngxWebrtcToggleAudioUser.connection.requestMuteAudio();
            this.isEnabled = !this.isEnabled;
            this.isDisabled = !this.isDisabled;
        }
    }
}
ToggleAudioUserDirective.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ToggleAudioUserDirective, deps: [], target: i0.ɵɵFactoryTarget.Directive });
ToggleAudioUserDirective.ɵdir = i0.ɵɵngDeclareDirective({ minVersion: "12.0.0", version: "13.2.1", type: ToggleAudioUserDirective, selector: "[ngxWebrtcToggleAudioUser]", inputs: { ngxWebrtcToggleAudioUser: "ngxWebrtcToggleAudioUser" }, host: { listeners: { "click": "onClick($event)" }, properties: { "class.disabled": "this.isDisabled", "class.enabled": "this.isEnabled" } }, ngImport: i0 });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ToggleAudioUserDirective, decorators: [{
            type: Directive,
            args: [{
                    selector: '[ngxWebrtcToggleAudioUser]',
                }]
        }], propDecorators: { ngxWebrtcToggleAudioUser: [{
                type: Input
            }], isDisabled: [{
                type: HostBinding,
                args: ['class.disabled']
            }], isEnabled: [{
                type: HostBinding,
                args: ['class.enabled']
            }], onClick: [{
                type: HostListener,
                args: ['click', ['$event']]
            }] } });

/**
 * Send a toggle video request to a specific peer connection.
 */
class ToggleVideoUserDirective {
    constructor() {
        this.ngxWebrtcToggleVideoUser = null;
        this.isDisabled = true;
        this.isEnabled = false;
    }
    onClick() {
        this.toggleUserVideo();
    }
    toggleUserVideo() {
        if (!this.ngxWebrtcToggleVideoUser) {
            console.warn('user not set');
            return;
        }
        if (this.ngxWebrtcToggleVideoUser?.connection) {
            this.ngxWebrtcToggleVideoUser.connection.requestMuteVideo();
            this.isEnabled = !this.isEnabled;
            this.isDisabled = !this.isDisabled;
        }
    }
}
ToggleVideoUserDirective.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ToggleVideoUserDirective, deps: [], target: i0.ɵɵFactoryTarget.Directive });
ToggleVideoUserDirective.ɵdir = i0.ɵɵngDeclareDirective({ minVersion: "12.0.0", version: "13.2.1", type: ToggleVideoUserDirective, selector: "[ngxWebrtcToggleVideoUser]", inputs: { ngxWebrtcToggleVideoUser: "ngxWebrtcToggleVideoUser" }, host: { listeners: { "click": "onClick($event)" }, properties: { "class.disabled": "this.isDisabled", "class.enabled": "this.isEnabled" } }, ngImport: i0 });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ToggleVideoUserDirective, decorators: [{
            type: Directive,
            args: [{
                    selector: '[ngxWebrtcToggleVideoUser]',
                }]
        }], propDecorators: { ngxWebrtcToggleVideoUser: [{
                type: Input
            }], isDisabled: [{
                type: HostBinding,
                args: ['class.disabled']
            }], isEnabled: [{
                type: HostBinding,
                args: ['class.enabled']
            }], onClick: [{
                type: HostListener,
                args: ['click', ['$event']]
            }] } });

var StreamType;
(function (StreamType) {
    StreamType["Video"] = "video";
    StreamType["Audio"] = "audio";
})(StreamType || (StreamType = {}));

var PeerConnectionClientSignalMessageType;
(function (PeerConnectionClientSignalMessageType) {
    PeerConnectionClientSignalMessageType["Candidate"] = "candidate";
    PeerConnectionClientSignalMessageType["Answer"] = "answer";
    PeerConnectionClientSignalMessageType["Offer"] = "offer";
    PeerConnectionClientSignalMessageType["Bye"] = "bye";
    PeerConnectionClientSignalMessageType["RequestMuteAudio"] = "request-mute-audio";
    PeerConnectionClientSignalMessageType["RequestMuteVideo"] = "request-mute-video";
    PeerConnectionClientSignalMessageType["AudioMuted"] = "audio-muted";
    PeerConnectionClientSignalMessageType["AudioUnmuted"] = "audio-unmuted";
    PeerConnectionClientSignalMessageType["VideoMuted"] = "video-muted";
    PeerConnectionClientSignalMessageType["VideoUnmuted"] = "video-unmuted";
    PeerConnectionClientSignalMessageType["StartShareScreen"] = "start-share-screen";
    PeerConnectionClientSignalMessageType["StopShareScreen"] = "stop-share-screen";
})(PeerConnectionClientSignalMessageType || (PeerConnectionClientSignalMessageType = {}));

class SdpUtils {
    static iceCandidateType(candidateStr) {
        return candidateStr.split(' ')[7];
    }
    static maybeSetOpusOptions(sdp, params) {
        // Set Opus in Stereo, if stereo is true, unset it, if stereo is false, and
        // do nothing if otherwise.
        if (params.opusStereo) {
            sdp = SdpUtils.setCodecParam(sdp, 'opus/48000', 'stereo', '1');
        }
        else if (!params.opusStereo) {
            sdp = SdpUtils.removeCodecParam(sdp, 'opus/48000', 'stereo');
        }
        // Set Opus FEC, if opusfec is true, unset it, if opusfec is false, and
        // do nothing if otherwise.
        if (params.opusFec) {
            sdp = SdpUtils.setCodecParam(sdp, 'opus/48000', 'useinbandfec', '1');
        }
        else if (!params.opusFec) {
            sdp = SdpUtils.removeCodecParam(sdp, 'opus/48000', 'useinbandfec');
        }
        // Set Opus DTX, if opusdtx is true, unset it, if opusdtx is false, and
        // do nothing if otherwise.
        if (params.opusDtx) {
            sdp = SdpUtils.setCodecParam(sdp, 'opus/48000', 'usedtx', '1');
        }
        else if (!params.opusDtx) {
            sdp = SdpUtils.removeCodecParam(sdp, 'opus/48000', 'usedtx');
        }
        // Set Opus maxplaybackrate, if requested.
        if (params.opusMaxPbr) {
            sdp = SdpUtils.setCodecParam(sdp, 'opus/48000', 'maxplaybackrate', params.opusMaxPbr);
        }
        return sdp;
    }
    static maybeSetAudioSendBitRate(sdp, params) {
        if (!params.audioSendBitrate) {
            return sdp;
        }
        // console.log('Prefer audio send bitrate: ' + params.audioSendBitrate);
        return SdpUtils.preferBitRate(sdp, params.audioSendBitrate, 'audio');
    }
    static maybeSetAudioReceiveBitRate(sdp, params) {
        if (!params.audioRecvBitrate) {
            return sdp;
        }
        // console.log('Prefer audio receive bitrate: ' + params.audioRecvBitrate);
        return SdpUtils.preferBitRate(sdp, params.audioRecvBitrate, 'audio');
    }
    static maybeSetVideoSendBitRate(sdp, params) {
        if (!params.videoSendBitrate) {
            return sdp;
        }
        // console.log('Prefer video send bitrate: ' + params.videoSendBitrate);
        return SdpUtils.preferBitRate(sdp, params.videoSendBitrate, 'video');
    }
    static maybeSetVideoReceiveBitRate(sdp, params) {
        if (!params.videoRecvBitrate) {
            return sdp;
        }
        // console.log('Prefer video receive bitrate: ' + params.videoRecvBitrate);
        return SdpUtils.preferBitRate(sdp, params.videoRecvBitrate, 'video');
    }
    // Add a b=AS:bitrate line to the m=mediaType section.
    static preferBitRate(sdp, bitrate, mediaType) {
        const sdpLines = sdp.split('\r\n');
        // Find m line for the given mediaType.
        const mLineIndex = SdpUtils.findLine(sdpLines, 'm=', mediaType);
        if (mLineIndex === null) {
            // console.log('Failed to add bandwidth line to sdp, as no m-line found');
            return sdp;
        }
        // Find next m-line if any.
        let nextMLineIndex = SdpUtils.findLineInRange(sdpLines, mLineIndex + 1, -1, 'm=');
        if (nextMLineIndex === null) {
            nextMLineIndex = sdpLines.length;
        }
        // Find c-line corresponding to the m-line.
        const cLineIndex = SdpUtils.findLineInRange(sdpLines, mLineIndex + 1, nextMLineIndex, 'c=');
        if (cLineIndex === null) {
            // console.log('Failed to add bandwidth line to sdp, as no c-line found');
            return sdp;
        }
        // Check if bandwidth line already exists between c-line and next m-line.
        const bLineIndex = SdpUtils.findLineInRange(sdpLines, cLineIndex + 1, nextMLineIndex, 'b=AS');
        if (bLineIndex) {
            sdpLines.splice(bLineIndex, 1);
        }
        // Create the b (bandwidth) sdp line.
        const bwLine = 'b=AS:' + bitrate;
        // As per RFC 4566, the b line should follow after c-line.
        sdpLines.splice(cLineIndex + 1, 0, bwLine);
        sdp = sdpLines.join('\r\n');
        return sdp;
    }
    // Add an a=fmtp: x-google-min-bitrate=kbps line, if videoSendInitialBitrate
    // is specified. We'll also add a x-google-min-bitrate value, since the max
    // must be >= the min.
    static maybeSetVideoSendInitialBitRate(sdp, params) {
        if (!params.videoSendInitialBitrate) {
            return sdp;
        }
        let initialBitrate = typeof params.videoSendInitialBitrate === 'string' ?
            parseInt(params.videoSendInitialBitrate, 10) : params.videoSendInitialBitrate;
        if (!initialBitrate) {
            return sdp;
        }
        // Validate the initial bitrate value.
        let maxBitrate = (typeof initialBitrate === 'string') ? parseInt(initialBitrate, 10) : initialBitrate;
        if (params.videoSendBitrate) {
            const bitrate = typeof params.videoSendBitrate === 'string' ?
                parseInt(params.videoSendBitrate, 10) : params.videoSendBitrate;
            if (bitrate) {
                if (initialBitrate > bitrate) {
                    // console.log('Clamping initial bitrate to max bitrate of ' + bitrate + ' kbps.');
                    initialBitrate = bitrate;
                    params.videoSendInitialBitrate = initialBitrate;
                }
                maxBitrate = bitrate;
            }
        }
        const sdpLines = sdp.split('\r\n');
        // Search for m line.
        const mLineIndex = SdpUtils.findLine(sdpLines, 'm=', 'video');
        if (mLineIndex === null) {
            // console.log('Failed to find video m-line');
            return sdp;
        }
        // Figure out the first codec payload type on the m=video SDP line.
        const videoMLine = sdpLines[mLineIndex];
        const pattern = new RegExp('m=video\\s\\d+\\s[A-Z/]+\\s');
        const sendPayloadType = videoMLine.split(pattern)[1].split(' ')[0];
        const line = SdpUtils.findLine(sdpLines, 'a=rtpmap', sendPayloadType);
        if (!line) {
            return sdp;
        }
        const fmtpLine = sdpLines[line];
        const codecName = fmtpLine.split('a=rtpmap:' +
            sendPayloadType)[1].split('/')[0];
        // Use codec from params if specified via URL param, otherwise use from SDP.
        const codec = params.videoSendCodec || codecName;
        sdp = SdpUtils.setCodecParam(sdp, codec, 'x-google-min-bitrate', params.videoSendInitialBitrate.toString());
        sdp = SdpUtils.setCodecParam(sdp, codec, 'x-google-max-bitrate', maxBitrate.toString());
        return sdp;
    }
    static removePayloadTypeFromMline(mLine, payloadType) {
        const mLineArray = mLine.split(' ');
        for (let i = 0; i < mLineArray.length; ++i) {
            if (mLineArray[i] === payloadType.toString()) {
                mLineArray.splice(i, 1);
            }
        }
        return mLineArray.join(' ');
    }
    static removeCodecByName(sdpLines, codec) {
        const index = SdpUtils.findLine(sdpLines, 'a=rtpmap', codec);
        if (index === null) {
            return sdpLines;
        }
        const payloadType = SdpUtils.getCodecPayloadTypeFromLine(sdpLines[index]);
        if (!payloadType) {
            return sdpLines;
        }
        sdpLines.splice(index, 1);
        // Search for the video m= line and remove the codec.
        const mLineIndex = SdpUtils.findLine(sdpLines, 'm=', 'video');
        if (mLineIndex === null) {
            return sdpLines;
        }
        sdpLines[mLineIndex] = SdpUtils.removePayloadTypeFromMline(sdpLines[mLineIndex], payloadType);
        return sdpLines;
    }
    static removeCodecByPayloadType(sdpLines, payloadType) {
        const index = SdpUtils.findLine(sdpLines, 'a=rtpmap', payloadType.toString());
        if (index === null) {
            return sdpLines;
        }
        sdpLines.splice(index, 1);
        // Search for the video m= line and remove the codec.
        const mLineIndex = SdpUtils.findLine(sdpLines, 'm=', 'video');
        if (mLineIndex === null) {
            return sdpLines;
        }
        sdpLines[mLineIndex] = SdpUtils.removePayloadTypeFromMline(sdpLines[mLineIndex], payloadType);
        return sdpLines;
    }
    static maybeRemoveVideoFec(sdp, params) {
        if (params.videoFec !== false) {
            return sdp;
        }
        let sdpLines = sdp.split('\r\n');
        let index = SdpUtils.findLine(sdpLines, 'a=rtpmap', 'red');
        if (index === null) {
            return sdp;
        }
        const redPayloadType = SdpUtils.getCodecPayloadTypeFromLine(sdpLines[index]);
        if (redPayloadType === null) {
            return sdp;
        }
        sdpLines = SdpUtils.removeCodecByPayloadType(sdpLines, redPayloadType);
        sdpLines = SdpUtils.removeCodecByName(sdpLines, 'ulpfec');
        // Remove fmtp lines associated with red codec.
        index = SdpUtils.findLine(sdpLines, 'a=fmtp', redPayloadType.toString());
        if (index === null) {
            return sdp;
        }
        const fmtpLine = SdpUtils.parseFmtpLine(sdpLines[index]);
        const rtxPayloadType = fmtpLine?.pt;
        if (!rtxPayloadType || rtxPayloadType === null) {
            return sdp;
        }
        sdpLines.splice(index, 1);
        sdpLines = SdpUtils.removeCodecByPayloadType(sdpLines, rtxPayloadType);
        return sdpLines.join('\r\n');
    }
    // Promotes |audioSendCodec| to be the first in the m=audio line, if set.
    static maybePreferAudioSendCodec(sdp, params) {
        return SdpUtils.maybePreferCodec(sdp, 'audio', 'send', params.audioSendCodec);
    }
    // Promotes |audioRecvCodec| to be the first in the m=audio line, if set.
    static maybePreferAudioReceiveCodec(sdp, params) {
        return SdpUtils.maybePreferCodec(sdp, 'audio', 'receive', params.audioRecvCodec);
    }
    // Promotes |videoSendCodec| to be the first in the m=audio line, if set.
    static maybePreferVideoSendCodec(sdp, params) {
        return SdpUtils.maybePreferCodec(sdp, 'video', 'send', params.videoSendCodec);
    }
    // Promotes |videoRecvCodec| to be the first in the m=audio line, if set.
    static maybePreferVideoReceiveCodec(sdp, params) {
        return SdpUtils.maybePreferCodec(sdp, 'video', 'receive', params.videoRecvCodec);
    }
    // Sets |codec| as the default |type| codec if it's present.
    // The format of |codec| is 'NAME/RATE', e.g. 'opus/48000'.
    static maybePreferCodec(sdp, type, dir, codec) {
        // let str = type + ' ' + dir + ' codec';
        if (!codec) {
            // console.log('No preference on ' + str + '.');
            return sdp;
        }
        // console.log('Prefer ' + str + ': ' + codec);
        const sdpLines = sdp.split('\r\n');
        // Search for m line.
        const mLineIndex = SdpUtils.findLine(sdpLines, 'm=', type);
        if (mLineIndex === null) {
            return sdp;
        }
        // If the codec is available, set it as the default in m line.
        let payload = null;
        // Iterate through rtpmap enumerations to find all matching codec entries
        for (let i = sdpLines.length - 1; i >= 0; --i) {
            // Finds first match in rtpmap
            const index = SdpUtils.findLineInRange(sdpLines, i, 0, 'a=rtpmap', codec, 'desc');
            if (index !== null) {
                // Skip all of the entries between i and index match
                i = index;
                payload = SdpUtils.getCodecPayloadTypeFromLine(sdpLines[index]);
                if (payload) {
                    // Move codec to top
                    sdpLines[mLineIndex] = SdpUtils.setDefaultCodec(sdpLines[mLineIndex], payload);
                }
            }
            else {
                // No match means we can break the loop
                break;
            }
        }
        sdp = sdpLines.join('\r\n');
        return sdp;
    }
    // Set fmtp param to specific codec in SDP. If param does not exists, add it.
    static setCodecParam(sdp, codec, param, value) {
        const sdpLines = sdp.split('\r\n');
        const fmtpLineIndex = SdpUtils.findFmtpLine(sdpLines, codec);
        let fmtpObj = { pt: '', params: {} };
        if (fmtpLineIndex === null) {
            const index = SdpUtils.findLine(sdpLines, 'a=rtpmap', codec);
            if (index === null) {
                return sdp;
            }
            const payload = SdpUtils.getCodecPayloadTypeFromLine(sdpLines[index]);
            if (payload === null) {
                return sdp;
            }
            fmtpObj.pt = payload.toString();
            fmtpObj.params = {};
            fmtpObj.params[param] = value;
            const result = SdpUtils.writeFmtpLine(fmtpObj);
            if (result) {
                sdpLines.splice(index + 1, 0, result);
            }
        }
        else {
            fmtpObj = SdpUtils.parseFmtpLine(sdpLines[fmtpLineIndex]);
            if (fmtpObj) {
                fmtpObj.params[param] = value;
                const result = SdpUtils.writeFmtpLine(fmtpObj);
                if (result) {
                    sdpLines[fmtpLineIndex] = result;
                }
            }
        }
        sdp = sdpLines.join('\r\n');
        return sdp;
    }
    // Remove fmtp param if it exists.
    static removeCodecParam(sdp, codec, param) {
        const sdpLines = sdp.split('\r\n');
        const fmtpLineIndex = SdpUtils.findFmtpLine(sdpLines, codec);
        if (fmtpLineIndex === null) {
            return sdp;
        }
        const map = SdpUtils.parseFmtpLine(sdpLines[fmtpLineIndex]);
        if (map === null) {
            return sdp;
        }
        delete map.params[param];
        const newLine = SdpUtils.writeFmtpLine(map);
        if (newLine === null) {
            sdpLines.splice(fmtpLineIndex, 1);
        }
        else {
            sdpLines[fmtpLineIndex] = newLine;
        }
        sdp = sdpLines.join('\r\n');
        return sdp;
    }
    // Split an fmtp line into an object including 'pt' and 'params'.
    static parseFmtpLine(fmtpLine) {
        const fmtpObj = { pt: '', params: {} };
        const spacePos = fmtpLine.indexOf(' ');
        const keyValues = fmtpLine.substring(spacePos + 1).split(';');
        const pattern = new RegExp('a=fmtp:(\\d+)');
        const result = fmtpLine.match(pattern);
        if (result && result.length === 2) {
            fmtpObj.pt = result[1];
        }
        else {
            return null;
        }
        const params = {};
        for (const pairString of keyValues) {
            const pair = pairString.split('=');
            if (pair.length === 2) {
                params[pair[0]] = pair[1];
            }
        }
        fmtpObj.params = params;
        return fmtpObj;
    }
    // Generate an fmtp line from an object including 'pt' and 'params'.
    static writeFmtpLine(fmtpObj) {
        if (!Object.prototype.hasOwnProperty.call(fmtpObj, 'pt') || !Object.prototype.hasOwnProperty.call(fmtpObj, 'params')) {
            return null;
        }
        const pt = fmtpObj.pt;
        const params = fmtpObj.params;
        const keyValues = [];
        let i = 0;
        for (const key in params) {
            if (params[key]) {
                keyValues[i] = key + '=' + params[key];
                ++i;
            }
        }
        if (i === 0) {
            return null;
        }
        return 'a=fmtp:' + pt?.toString() + ' ' + keyValues.join(';');
    }
    // Find fmtp attribute for |codec| in |sdpLines|.
    static findFmtpLine(sdpLines, codec) {
        // Find payload of codec.
        const payload = SdpUtils.getCodecPayloadType(sdpLines, codec);
        // Find the payload in fmtp line.
        return payload ? SdpUtils.findLine(sdpLines, 'a=fmtp:' + payload.toString()) : null;
    }
    // Find the line in sdpLines that starts with |prefix|, and, if specified,
    // contains |substr| (case-insensitive search).
    static findLine(sdpLines, prefix, substr) {
        return SdpUtils.findLineInRange(sdpLines, 0, -1, prefix, substr);
    }
    // Find the line in sdpLines[startLine...endLine - 1] that starts with |prefix|
    // and, if specified, contains |substr| (case-insensitive search).
    static findLineInRange(sdpLines, startLine, endLine, prefix, substr, direction) {
        if (direction === undefined) {
            direction = 'asc';
        }
        direction = direction || 'asc';
        if (direction === 'asc') {
            // Search beginning to end
            const realEndLine = endLine !== -1 ? endLine : sdpLines.length;
            for (let i = startLine; i < realEndLine; ++i) {
                if (prefix && sdpLines[i].indexOf(prefix) === 0) {
                    if (!substr ||
                        sdpLines[i].toLowerCase().indexOf(substr.toLowerCase()) !== -1) {
                        return i;
                    }
                }
            }
        }
        else {
            // Search end to beginning
            const realStartLine = startLine !== -1 ? startLine : sdpLines.length - 1;
            for (let j = realStartLine; j >= 0; --j) {
                if (prefix && sdpLines[j].indexOf(prefix) === 0) {
                    if (!substr ||
                        sdpLines[j].toLowerCase().indexOf(substr.toLowerCase()) !== -1) {
                        return j;
                    }
                }
            }
        }
        return null;
    }
    // Gets the codec payload type from sdp lines.
    static getCodecPayloadType(sdpLines, codec) {
        const index = SdpUtils.findLine(sdpLines, 'a=rtpmap', codec);
        return index ? SdpUtils.getCodecPayloadTypeFromLine(sdpLines[index]) : null;
    }
    // Gets the codec payload type from an a=rtpmap:X line.
    static getCodecPayloadTypeFromLine(sdpLine) {
        const pattern = new RegExp('a=rtpmap:(\\d+) [a-zA-Z0-9-]+\\/\\d+');
        const result = sdpLine.match(pattern);
        return (result && result.length === 2) ? result[1] : null;
    }
    // Returns a new m= line with the specified codec as the first one.
    static setDefaultCodec(mLine, payload) {
        const elements = mLine.split(' ');
        // Just copy the first three parameters; codec order starts on fourth.
        const newLine = elements.slice(0, 3);
        // Put target payload first and copy in the rest.
        newLine.push(payload);
        for (let i = 3; i < elements.length; i++) {
            if (elements[i] !== payload) {
                newLine.push(elements[i]);
            }
        }
        return newLine.join(' ');
    }
}

class UtilityService {
    static getRandom(size) {
        return `${Math.round(Math.random() * parseInt(`1${(1e15 + 0 + '').slice(-size)}`, 10))}`;
    }
}
UtilityService.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: UtilityService, deps: [], target: i0.ɵɵFactoryTarget.Injectable });
UtilityService.ɵprov = i0.ɵɵngDeclareInjectable({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: UtilityService, providedIn: 'root' });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: UtilityService, decorators: [{
            type: Injectable,
            args: [{
                    providedIn: 'root'
                }]
        }] });

class PeerConnectionClient {
    constructor(settings) {
        this.started = false;
        this.isInitiator = false;
        this.hasRemoteSdp = false;
        this.messageQueue = [];
        this.isNegotiating = false;
        this.id = UtilityService.getRandom(6);
        this.DEFAULT_SDP_OFFER_OPTIONS = {
            offerToReceiveAudio: true,
            offerToReceiveVideo: true,
        };
        /**
         * messages send by the peer connection
         */
        this.signalingMessage = new EventEmitter();
        /**
         * triggered when new candidate is available initial value is `null`
         */
        this.seeNewCandidate$ = new BehaviorSubject(null);
        /**
         * triggered when a remote stream is added @deprecated use remoteTrackAdded
         */
        this.remoteStreamAdded = new EventEmitter();
        /**
         * triggered when a remote track is added
         */
        this.remoteTrackAdded = new EventEmitter();
        /**
         * triggered when the `RTCSignalingState` is changed inital value is `null`
         */
        this.signalState$ = new BehaviorSubject(null);
        /**
         * triggered if an error occure inital value is `null`
         */
        this.error$ = new BehaviorSubject(null);
        /**
         * triggered when the connected user toggle share screen, inital value is `false`
         */
        this.useShareScreen$ = new BehaviorSubject(false);
        /**
         * triggered when remote description is set, inital value is `null`
         */
        this.remotesDescriptionSet = new BehaviorSubject(null);
        /**
         * triggered when connected user close connection
         */
        this.remoteHangUp = new EventEmitter();
        /**
         * triggered when the connected user asks for mute user audio
         */
        this.muteMyAudio = new EventEmitter();
        /**
         * triggered when the connected user asks for mute user video
         */
        this.muteMyVideo = new EventEmitter();
        /**
         * triggered when the connected user mutes his video
         */
        this.userMuteVideo = new EventEmitter();
        /**
         * triggered when the connected user unmutes his video
         */
        this.userUnmuteVideo = new EventEmitter();
        /**
         * triggered when the connected user mutes his audio
         */
        this.userMuteAudio = new EventEmitter();
        /**
         * triggered when the connected user unmutes his audio
         */
        this.userUnmuteAudio = new EventEmitter();
        /**
         * triggerd on need negotiation
         */
        this.negotiationNeededTriggered = new Subject();
        /**
         * triggered on I see connection state changed, inital value is `null`
         */
        this.iceConnectionState$ = new BehaviorSubject(null);
        this.startTime = performance.now();
        this.settings = settings;
        this.log(this.settings.peerConnectionConfig);
        this.connection = new RTCPeerConnection(this.settings.peerConnectionConfig);
        if (this.settings.debug) {
            window.rtcpc = this.connection;
        }
        this.connection.onicecandidate = this.onIceCandidate.bind(this);
        this.connection.ontrack = this.onRemoteTrackAdded.bind(this);
        this.connection.onsignalingstatechange = this.onSignalingStateChange.bind(this);
        this.connection.oniceconnectionstatechange = this.onIceConnectionStateChange.bind(this);
        this.connection.onnegotiationneeded = this.onnegotiationneeded.bind(this);
    }
    /**
     * Start Peer connection as caller
     * @link https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/createOffer
     * @param offerOptions options for the connection
     *
     * @returns `true` when offer is made `false` if no connection available or the connection is already open
     */
    startAsCaller(offerOptions = {}) {
        this.log('startAsCaller', offerOptions);
        if (!this.connection) {
            return false;
        }
        if (this.started) {
            return false;
        }
        this.isInitiator = true;
        this.started = true;
        return this.createOffer(offerOptions);
    }
    createOffer(offerOptions = {}) {
        if (!this.connection) {
            return false;
        }
        const constraints = { ...this.DEFAULT_SDP_OFFER_OPTIONS, ...offerOptions };
        this.log('Sending offer to peer, with constraints: \n\'' + JSON.stringify(constraints) + '\'.');
        this.connection.createOffer(constraints)
            .then(this.setLocalSdpAndNotify.bind(this))
            .catch(this.onError.bind(this, 'createOffer'));
        return true;
    }
    /**
     * Start Peer connection as callee
     * @param initialMessages messages that are collected before the `PeerConnectionClient` instance is created
     * @returns `true` when messages are queed or processed `false` if no connection available or the connection is already open
     */
    startAsCallee(initialMessages) {
        this.log('startAsCallee', initialMessages);
        if (!this.connection) {
            this.error('startAsCallee()', 'no connection');
            return false;
        }
        if (this.started) {
            this.error('startAsCallee()', 'not started');
            return false;
        }
        this.started = true;
        if (initialMessages && initialMessages.length > 0) {
            // Convert received messages to JSON objects and add them to the message
            // queue.
            for (const message of initialMessages) {
                this.receiveSignalingMessage(message);
            }
            return true;
        }
        // We may have queued messages received from the signaling channel before
        // started.
        if (this.messageQueue.length > 0) {
            this.drainMessageQueue();
        }
        return true;
    }
    /**
     * send `PeerConnectionClientSignalMessageType.Bye` message to connected user and close the open connection
     */
    close() {
        this.log('close');
        if (!this.connection) {
            return;
        }
        this.signalingMessage.emit({
            type: PeerConnectionClientSignalMessageType.Bye
        });
        this.connection.close();
        this.connection = null;
    }
    /**
     * send `PeerConnectionClientSignalMessageType.AudioMuted` message to connected user
     */
    audioMuted() {
        if (!this.connection) {
            return;
        }
        this.signalingMessage.emit({
            type: PeerConnectionClientSignalMessageType.AudioMuted
        });
    }
    /**
     * send `PeerConnectionClientSignalMessageType.AudioUnmuted` message to connected user
     */
    audioUnmuted() {
        if (!this.connection) {
            return;
        }
        this.signalingMessage.emit({
            type: PeerConnectionClientSignalMessageType.AudioUnmuted
        });
    }
    /**
     * send `PeerConnectionClientSignalMessageType.VideoMuted` message to connected user
     */
    videoMuted() {
        if (!this.connection) {
            return;
        }
        this.signalingMessage.emit({
            type: PeerConnectionClientSignalMessageType.VideoMuted
        });
    }
    /**
     * send `PeerConnectionClientSignalMessageType.VideoUnmuted` message to connected user
     */
    videoUnmuted() {
        if (!this.connection) {
            return;
        }
        this.signalingMessage.emit({
            type: PeerConnectionClientSignalMessageType.VideoUnmuted
        });
    }
    /**
     * send `PeerConnectionClientSignalMessageType.RequestMuteAudio` message to connected user
     */
    requestMuteAudio() {
        this.log('requestMuteAudio');
        if (!this.connection) {
            return;
        }
        this.signalingMessage.emit({
            type: PeerConnectionClientSignalMessageType.RequestMuteAudio
        });
    }
    /**
     * send `PeerConnectionClientSignalMessageType.RequestMuteVideo` message to connected user
     */
    requestMuteVideo() {
        this.log('requestMuteVideo');
        if (!this.connection) {
            return;
        }
        this.signalingMessage.emit({
            type: PeerConnectionClientSignalMessageType.RequestMuteVideo
        });
    }
    /**
     * send `PeerConnectionClientSignalMessageType.StartShareScreen` message to connected user
     */
    startShareScreen() {
        this.log('startShareScreen');
        if (!this.connection) {
            return;
        }
        this.signalingMessage.emit({
            type: PeerConnectionClientSignalMessageType.StartShareScreen
        });
    }
    /**
     * send `PeerConnectionClientSignalMessageType.StopShareScreen` message to connected user
     */
    stopShareScreen() {
        this.log('startShareScreen');
        if (!this.connection) {
            return;
        }
        this.signalingMessage.emit({
            type: PeerConnectionClientSignalMessageType.StopShareScreen
        });
    }
    /**
     * get peer connection state
     * @returns `null` if not connected otherwiese an object of `RTCSignalingState`, `RTCIceGatheringState` and `RTCIceConnectionState`
     */
    getPeerConnectionStates() {
        if (!this.connection) {
            return null;
        }
        return {
            signalingState: this.connection.signalingState,
            iceGatheringState: this.connection.iceGatheringState,
            iceConnectionState: this.connection.iceConnectionState
        };
    }
    /**
     * get the connection stats of a track in the connection
     * @param track `MediaStreamTrack` to check state for
     * @returns Promise that resolves to `RTCStatsReport`
     */
    getPeerConnectionStats(track) {
        if (!this.connection) {
            return Promise.reject();
        }
        return this.connection.getStats(track);
    }
    /**
     * add a `MediaStreamTrack` to the connection
     * @param track `MediaStreamTrack` to be added to the connection.
     */
    addTrack(track) {
        this.log('addTrack', track);
        if (this.connection) {
            const sender = this.connection.getSenders().find((s) => {
                return s?.track?.kind === track.kind;
            });
            if (sender?.track) {
                this.log('existing track found using replaceTrack instead');
                this.replaceTrack(track);
            }
            else {
                this.connection.addTrack(track);
            }
        }
    }
    /**
     * replace current `MediaStreamTrack` with new from parameter
     * @param track new `MediaStreamTrack`
     */
    replaceTrack(track) {
        this.log(track);
        if (this.connection) {
            const sender = this.connection.getSenders().find((s) => {
                return s?.track?.kind === track.kind;
            });
            if (!sender?.track) {
                this.log('no track found using addTrack instead');
                this.addTrack(track);
            }
            else {
                sender.replaceTrack(track);
            }
        }
    }
    /**
     * Add all `MediaStreamTrack`s of a `MediaStream` to the connection
     * @param mediaSteam `MediaStream` with tracks
     */
    addStream(mediaSteam) {
        this.log('addStream', mediaSteam);
        mediaSteam.getTracks().forEach(track => {
            this.addTrack(track);
        });
    }
    setLocalSdpAndNotify(sessionDescription) {
        if (!this.connection) {
            return;
        }
        // this.log('setLocalSdpAndNotify', sessionDescription);
        if (sessionDescription.sdp) {
            sessionDescription.sdp = SdpUtils.maybeSetOpusOptions(sessionDescription.sdp, this.settings);
            sessionDescription.sdp = SdpUtils.maybePreferAudioReceiveCodec(sessionDescription.sdp, this.settings);
            sessionDescription.sdp = SdpUtils.maybePreferVideoReceiveCodec(sessionDescription.sdp, this.settings);
            sessionDescription.sdp = SdpUtils.maybeSetAudioReceiveBitRate(sessionDescription.sdp, this.settings);
            sessionDescription.sdp = SdpUtils.maybeSetVideoReceiveBitRate(sessionDescription.sdp, this.settings);
            sessionDescription.sdp = SdpUtils.maybeRemoveVideoFec(sessionDescription.sdp, this.settings);
        }
        this.connection.setLocalDescription(sessionDescription)
            .then(() => this.log('Set session description success.'))
            .catch(this.onError.bind(this, 'setLocalDescription'));
        // Chrome version of RTCSessionDescription can't be serialized directly
        // because it JSON.stringify won't include attributes which are on the
        // object's prototype chain. By creating the message to serialize
        // explicitly we can avoid the issue.
        this.signalingMessage.emit({
            sdp: sessionDescription.sdp,
            type: sessionDescription.type
        });
    }
    filterIceCandidate(candidateObj) {
        // this.log('filterIceCandidate', candidateObj);
        const candidateStr = candidateObj.candidate;
        // Always remove TCP candidates. Not needed in this context.
        if (candidateStr.indexOf('tcp') !== -1) {
            return false;
        }
        // If we're trying to remove non-relay candidates, do that.
        if (this.settings.peerConnectionConfig.iceTransports === 'relay' && SdpUtils.iceCandidateType(candidateStr) !== 'relay') {
            return false;
        }
        return true;
    }
    onIceCandidate(event) {
        // this.log('onIceCandidate', event);
        if (event.candidate) {
            // Eat undesired candidates.
            if (this.filterIceCandidate(event.candidate)) {
                const message = {
                    type: PeerConnectionClientSignalMessageType.Candidate,
                    label: event.candidate.sdpMLineIndex,
                    id: event.candidate.sdpMid,
                    candidate: event.candidate.candidate
                };
                this.signalingMessage.emit(message);
                this.onRecordIceCandidate('Local', event.candidate);
            }
        }
        else {
            this.log('End of candidates.');
        }
    }
    handleMessageEvents(messageObj) {
        if (messageObj.type === PeerConnectionClientSignalMessageType.Bye) {
            this.remoteHangUp.emit();
        }
        else if (messageObj.type === PeerConnectionClientSignalMessageType.RequestMuteAudio) {
            this.muteMyAudio.emit();
        }
        else if (messageObj.type === PeerConnectionClientSignalMessageType.RequestMuteVideo) {
            this.muteMyVideo.emit();
        }
        else if (messageObj.type === PeerConnectionClientSignalMessageType.AudioMuted) {
            this.userMuteAudio.emit();
        }
        else if (messageObj.type === PeerConnectionClientSignalMessageType.AudioUnmuted) {
            this.userUnmuteAudio.emit();
        }
        else if (messageObj.type === PeerConnectionClientSignalMessageType.VideoMuted) {
            this.userMuteVideo.emit();
        }
        else if (messageObj.type === PeerConnectionClientSignalMessageType.VideoUnmuted) {
            this.userUnmuteVideo.emit();
        }
        else if (messageObj.type === PeerConnectionClientSignalMessageType.StartShareScreen) {
            this.useShareScreen$.next(true);
        }
        else if (messageObj.type === PeerConnectionClientSignalMessageType.StopShareScreen) {
            this.useShareScreen$.next(false);
        }
    }
    /**
     * execute this methode to set messages in the peer connection. You need a connection lay to receive messages.
     * @param message message to process
     */
    receiveSignalingMessage(message) {
        this.log('receiveSignalingMessage', message);
        let messageObj;
        if (typeof message === 'string') {
            try {
                messageObj = JSON.parse(message);
            }
            catch (error) {
                this.log('invalid json for message', message);
                return;
            }
        }
        else {
            messageObj = message;
        }
        if (this.connection?.iceGatheringState === 'complete' ||
            ((this.isInitiator && messageObj.type === PeerConnectionClientSignalMessageType.Answer) ||
                (!this.isInitiator && messageObj.type === PeerConnectionClientSignalMessageType.Offer))) {
            this.hasRemoteSdp = true;
            // Always process offer before candidates.
            this.messageQueue.unshift(messageObj);
        }
        if (messageObj.type === PeerConnectionClientSignalMessageType.Candidate) {
            this.messageQueue.push(messageObj);
        }
        this.handleMessageEvents(messageObj);
        this.drainMessageQueue();
    }
    processSignalingMessage(message) {
        this.log('processSignalingMessage', message);
        if (!this.connection) {
            return;
        }
        this.handleMessageEvents(message);
        if (message.type === PeerConnectionClientSignalMessageType.Offer && (!this.isInitiator || this.connection.iceGatheringState === 'complete')) {
            if (this.connection.signalingState !== 'stable') {
                this.log('ERROR: remote offer received in unexpected state: ' + this.connection.signalingState);
                return;
            }
            this.setRemoteSdp(message);
            this.doAnswer();
        }
        else if (message.type === PeerConnectionClientSignalMessageType.Answer && (this.isInitiator || this.connection.iceGatheringState === 'complete')) {
            if (this.connection.signalingState !== 'have-local-offer') {
                this.log('ERROR: remote answer received in unexpected state: ' +
                    this.connection.signalingState);
                return;
            }
            this.setRemoteSdp(message);
        }
        else if (message.type === PeerConnectionClientSignalMessageType.Candidate) {
            const candidate = new RTCIceCandidate({
                sdpMLineIndex: message.label,
                candidate: message.candidate
            });
            this.onRecordIceCandidate('Remote', candidate);
            this.connection.addIceCandidate(candidate)
                .then(this.log.bind(this, 'Remote candidate added successfully.'))
                .catch(this.onError.bind(this, 'addIceCandidate'));
        }
        else {
            this.log(`WARNING: unexpected message: ${message.type}`);
        }
    }
    doAnswer() {
        if (!this.connection) {
            return;
        }
        this.log('Sending answer to peer.');
        this.connection.createAnswer()
            .then(this.setLocalSdpAndNotify.bind(this))
            .catch(this.onError.bind(this, 'createAnswer'));
    }
    setRemoteSdp(message) {
        if (!this.connection) {
            return;
        }
        // this.log('setRemoteSdp', message);
        if (message.sdp) {
            message.sdp = SdpUtils.maybeSetOpusOptions(message.sdp, this.settings);
            message.sdp = SdpUtils.maybePreferAudioSendCodec(message.sdp, this.settings);
            message.sdp = SdpUtils.maybePreferVideoSendCodec(message.sdp, this.settings);
            message.sdp = SdpUtils.maybeSetAudioSendBitRate(message.sdp, this.settings);
            message.sdp = SdpUtils.maybeSetVideoSendBitRate(message.sdp, this.settings);
            message.sdp = SdpUtils.maybeSetVideoSendInitialBitRate(message.sdp, this.settings);
            message.sdp = SdpUtils.maybeRemoveVideoFec(message.sdp, this.settings);
        }
        this.connection.setRemoteDescription(new RTCSessionDescription(message))
            .then(this.onSetRemoteDescriptionSuccess.bind(this))
            .catch(this.onError.bind(this, 'setRemoteDescription'));
    }
    // When we receive messages from GAE registration and from the WSS connection,
    // we add them to a queue and drain it if conditions are right.
    drainMessageQueue() {
        // It's possible that we finish registering and receiving messages from WSS
        // before our peer connection is created or started. We need to wait for the
        // peer connection to be created and started before processing messages.
        //
        // Also, the order of messages is in general not the same as the POST order
        // from the other client because the POSTs are async and the server may handle
        // some requests faster than others. We need to process offer before
        // candidates so we wait for the offer to arrive first if we're answering.
        // Offers are added to the front of the queue.
        if (!this.connection || !this.started || !this.hasRemoteSdp) {
            return;
        }
        for (const message of this.messageQueue) {
            this.processSignalingMessage(message);
        }
        this.messageQueue = [];
    }
    // Hooks
    onIceConnectionStateChange() {
        if (!this.connection) {
            return;
        }
        this.log('ICE connection state changed to: ' + this.connection.iceConnectionState);
        if (this.connection.iceConnectionState === 'completed') {
            this.log('ICE complete time: ' +
                (window.performance.now() - this.startTime).toFixed(0) + 'ms.');
        }
        this.iceConnectionState$.next(this.connection.iceConnectionState);
    }
    onnegotiationneeded() {
        if (!this.connection) {
            return;
        }
        this.log('onnegotiationneeded');
        this.negotiationNeededTriggered.next(true);
    }
    onSignalingStateChange() {
        if (!this.connection) {
            return;
        }
        this.isNegotiating = (this.connection.signalingState !== 'stable');
        this.log('Signaling state changed to: ' + this.connection.signalingState);
        this.signalState$.next(this.connection.signalingState);
    }
    onError(source, error) {
        this.log(`${source}:`, error);
        this.error$.next({ source, error });
    }
    onRecordIceCandidate(location, candidateObj) {
        if (candidateObj?.candidate) {
            this.seeNewCandidate$.next({ location, candidate: candidateObj.candidate });
        }
        else {
            this.log('see new candidate but candidate is null', { location, candidate: candidateObj });
        }
    }
    onRemoteTrackAdded(event) {
        this.remoteStreamAdded.emit({
            track: event.track,
            kind: event.track.kind
        });
        this.remoteTrackAdded.emit({
            track: event.track,
            kind: event.track.kind
        });
    }
    onSetRemoteDescriptionSuccess() {
        if (!this.connection) {
            return;
        }
        this.log('Set remote session description success.');
        // By now all onaddstream events for the setRemoteDescription have fired,
        // so we can know if the peer has any remote video streams that we need
        // to wait for. Otherwise, transition immediately to the active state.
        const remoteStreams = this.connection.getReceivers();
        if (remoteStreams.length) {
            for (const stream of remoteStreams) {
                this.remotesDescriptionSet.next(stream.track);
            }
        }
    }
    log(...args) {
        if (this.settings.debug) {
            console.log(this.id, ...args);
        }
    }
    error(...args) {
        if (this.settings.debug) {
            console.error(this.id, ...args);
        }
    }
}

class Configuration {
    constructor() {
        this.userIdentifier = '';
        this.debug = false;
        this.savePreferredDeviceInStorage = true;
    }
}

const NGX_WEBRTC_STORAGE = new InjectionToken('NGX_WEBRTC_STORAGE');

/**
 * The CallService holds the state of the peer connection. It provides methods to update the state
 * and methods to create a `PeerConnectionClient`.
 */
class CallService {
    constructor(config, storage) {
        this.config = config;
        this.storage = storage;
        this.storage_key_since = 'ngx-webrtc-since';
        this.since = 0;
        // TODO: add option to configure this
        this.identifier = this.config.userIdentifier;
        /**
         * users in call state, add user via `CallService.addUser(User,...)` and remove user via `CallService.removeUser(User)`.
         * get all User via `CallService.getUsers()`, get one user via `CallService.getUser()`.
         */
        this.users$ = new BehaviorSubject([]);
        /**
         * Emitted by `ShareScreenDirective` when current User starts sharing his screen.
         */
        this.startShareScreen = new EventEmitter();
        /**
         * Emitted by `ShareScreenDirective` when current User stops sharing his screen.
         */
        this.stopShareScreen = new EventEmitter();
        /**
         * default public and free IceServers list
         * ```json
         * [
         *  { urls: 'stun:stun.l.google.com:19302' },
         *  { urls: 'stun:global.stun.twilio.com:3478?transport=udp' },
         *  { urls: 'stun:stun.services.mozilla.com' },
         * ]
         *
         * ```
         */
        this.defaultServers = [
            { urls: 'stun:stun.l.google.com:19302' },
            { urls: 'stun:global.stun.twilio.com:3478?transport=udp' },
            { urls: 'stun:stun.services.mozilla.com' },
        ];
        /**
         * chat status state
         */
        this.started$ = new BehaviorSubject(false);
    }
    /**
     * update since timestamp with current time
     */
    updateSince() {
        this.since = Date.now();
        // TODO: make storage customizable via provider
        window[this.storage].setItem(this.storage_key_since, `${this.since}`);
    }
    /**
     * get current since timestamp set by `CallService.updateSince()`
     * @returns Timestamp
     */
    getSince() {
        const storageSince = window[this.storage].getItem(this.storage_key_since);
        if (!this.since && storageSince && storageSince !== null) {
            this.since = parseInt(storageSince, 10);
        }
        return this.since;
    }
    /**
     * The `CallService` hold the users state with all users, with this methode you can add a user to the state.
     * @param user User object that contains userIdentifier
     * @param connection created connection for the user
     * @param node component that is used to display the users webcam, etc.
     */
    addUser(user, connection, node) {
        const users = this.getUsers();
        users.push({
            user,
            hasCam: false,
            hasMic: false,
            volume: 1,
            audioMuted: false,
            videoMuted: false,
            shareScreen: false,
            connection,
            node
        });
        this.users$.next(users);
    }
    /**
     * remove a user object from state
     * @param user User object to remove
     */
    removeUser(user) {
        let users = this.getUsers();
        users = users.filter(e => e.user[this.identifier] !== user[this.identifier]);
        this.users$.next(users);
    }
    /**
     * Use this method if the passed user has a camera to update the state.
     * @param user User to update
     */
    userHasCam(user) {
        const users = this.getUsers();
        const currentUser = this.findUser(users, user);
        if (currentUser) {
            currentUser.hasCam = true;
            this.users$.next(users);
        }
    }
    /**
     * Use this method if the passed user has a microphone to update the state.
     * @param user
     */
    userHasMic(user) {
        const users = this.getUsers();
        const currentUser = this.findUser(users, user);
        if (currentUser) {
            currentUser.hasMic = true;
            this.users$.next(users);
        }
    }
    /**
     * Use this method when the passed user deactivates his microphone to update the state.
     * @param user
     */
    userAudioMuted(user) {
        const users = this.getUsers();
        const currentUser = this.findUser(users, user);
        if (currentUser) {
            currentUser.audioMuted = true;
            this.users$.next(users);
        }
    }
    /**
     * Use this method when the passed user activates his microphone to update the state.
     * @param user
     */
    userAudioUnmuted(user) {
        const users = this.getUsers();
        const currentUser = this.findUser(users, user);
        if (currentUser) {
            currentUser.audioMuted = false;
            this.users$.next(users);
        }
    }
    /**
     * Use this method when the passed user deactivates his camera to update the state.
     * @param user
     */
    userVideoMuted(user) {
        const users = this.getUsers();
        const currentUser = this.findUser(users, user);
        if (currentUser) {
            currentUser.videoMuted = true;
            this.users$.next(users);
        }
    }
    /**
     * Use this method when the passed user activates his camera to update the state.
     * @param user
     */
    userVideoUnmuted(user) {
        const users = this.getUsers();
        const currentUser = this.findUser(users, user);
        if (currentUser) {
            currentUser.videoMuted = false;
            this.users$.next(users);
        }
    }
    /**
     * Use this method when the passed user starts to share his screen to update the state.
     * @param user
     */
    userStartShareScreen(user) {
        const users = this.getUsers();
        const currentUser = this.findUser(users, user);
        if (currentUser) {
            currentUser.shareScreen = true;
            this.users$.next(users);
        }
    }
    /**
     * Use this method when the passed user stops sharing his screen to update the state.
     * @param user
     */
    userStopShareScreen(user) {
        const users = this.getUsers();
        const currentUser = this.findUser(users, user);
        if (currentUser) {
            currentUser.shareScreen = false;
            this.users$.next(users);
        }
        this.users$.next(users);
    }
    /**
     * Give all users who are currently in the state.
     * @returns All users currently in state
     */
    getUsers() {
        return this.users$.getValue();
    }
    /**
     *
     * @param user User with `userIdentifier`
     * @returns User in state
     */
    getUser(user) {
        return this.getUsers().find(e => e.user[this.identifier] === user[this.identifier]) || null;
    }
    /**
     * Create a new `PeerConnectionClient` with the given settings
     * @param settings Settings for creating the `PeerConnectionClient`
     * @returns `PeerConnectionClient` object
     */
    async createPeerClient(settings) {
        return new PeerConnectionClient(settings);
    }
    /**
     * With this methode you can create a RTCCertificate to secure a connection.
     * @link https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/generateCertificate
     * @param algorithm Certificate options used by `RTCPeerConnection.generateCertificate()` Default algorithm `ECDSA` with curve `P-256`
     * @returns Promise resolve to `RTCCertificate`
     */
    async createCertifcate(algorithm = {
        name: 'ECDSA',
        namedCurve: 'P-256'
    }) {
        return RTCPeerConnection.generateCertificate(algorithm);
    }
    /**
     * set call state started to `true`, you can subscribe to `CallService.started$` for updates.
     */
    start() {
        this.started$.next(true);
    }
    /**
     * set call state started to `false`, you can subscribe to `CallService.started$` for updates.
     */
    stop() {
        this.started$.next(false);
    }
    /**
     * Configured user identifier.
     * @returns identifier to select a User
     */
    getUserIdentifier() {
        return this.identifier;
    }
    findUser(users, user) {
        return users.find(e => e.user[this.identifier] === user[this.identifier]) || null;
    }
}
CallService.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: CallService, deps: [{ token: Configuration }, { token: NGX_WEBRTC_STORAGE }], target: i0.ɵɵFactoryTarget.Injectable });
CallService.ɵprov = i0.ɵɵngDeclareInjectable({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: CallService, providedIn: 'root' });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: CallService, decorators: [{
            type: Injectable,
            args: [{
                    providedIn: 'root'
                }]
        }], ctorParameters: function () { return [{ type: Configuration }, { type: undefined, decorators: [{
                    type: Inject,
                    args: [NGX_WEBRTC_STORAGE]
                }] }]; } });

const NGX_WEBRTC_STORAGE_PREFIX = new InjectionToken('NGX_WEBRTC_STORAGE_PREFIX');

class PreferencesService {
    constructor(config, prefix, storage) {
        this.config = config;
        this.prefix = prefix;
        this.storage = storage;
        this.preferredAudioInputDevice$ = new BehaviorSubject(null);
        this.preferredAudioOutputDevice$ = new BehaviorSubject(null);
        this.preferredVideoInputDevice$ = new BehaviorSubject(null);
        this.preferredAudioInputDeviceVolume$ = new BehaviorSubject(null);
        this.VIDEO_INPUT_KEY = this.storageKey('preferred-video-input-device');
        this.AUDIO_INPUT_KEY = this.storageKey('preferred-audio-input-device');
        this.AUDIO_INPUT_VOLUME_KEY = this.storageKey('preferred-audio-input-device');
        this.AUDIO_OUTPUT_KEY = this.storageKey('preferred-audio-input-device');
        this.subs = [];
        this.initPreferredDevicesFromStorag();
    }
    ngOnDestroy() {
        this.subs.forEach(sub => {
            sub.unsubscribe();
        });
    }
    storageKey(key) {
        return [this.prefix, key].join('-');
    }
    initSubscription(subject, key) {
        this.subs.push(subject.subscribe(newValue => {
            if (typeof newValue === 'string' || typeof newValue === 'number') {
                window[this.storage].setItem(key, `${newValue}`);
            }
            else {
                window[this.storage].removeItem(key);
            }
        }));
    }
    setInitalValuesFromStorage() {
        this.preferredVideoInputDevice$.next(window[this.storage].getItem(this.VIDEO_INPUT_KEY));
        this.preferredAudioInputDevice$.next(window[this.storage].getItem(this.AUDIO_INPUT_KEY));
        const inputDeviceVolumeStorage = window[this.storage].getItem(this.AUDIO_INPUT_VOLUME_KEY);
        if (inputDeviceVolumeStorage) {
            const inputDeviceVolume = parseInt(inputDeviceVolumeStorage, 10);
            this.preferredAudioInputDeviceVolume$.next(inputDeviceVolume);
        }
        this.preferredAudioOutputDevice$.next(window[this.storage].getItem(this.AUDIO_OUTPUT_KEY));
    }
    initPreferredDevicesFromStorag() {
        if (this.config.savePreferredDeviceInStorage) {
            this.setInitalValuesFromStorage();
            this.initSubscription(this.preferredVideoInputDevice$, this.VIDEO_INPUT_KEY);
            this.initSubscription(this.preferredAudioInputDevice$, this.AUDIO_INPUT_KEY);
            this.initSubscription(this.preferredAudioOutputDevice$, this.AUDIO_OUTPUT_KEY);
            this.initSubscription(this.preferredAudioInputDeviceVolume$, this.AUDIO_INPUT_VOLUME_KEY);
        }
    }
    getAudioConstraintWithPreferences() {
        const preferredAudioInputDevice = this.preferredAudioInputDevice$.getValue();
        const preferredAudioInputDeviceVolume = this.preferredAudioInputDeviceVolume$.getValue();
        let audioConstraint = true;
        if (preferredAudioInputDevice || preferredAudioInputDeviceVolume !== null) {
            if (preferredAudioInputDevice && preferredAudioInputDeviceVolume !== null) {
                audioConstraint = {
                    deviceId: preferredAudioInputDevice,
                    volume: preferredAudioInputDeviceVolume
                };
            }
            else if (preferredAudioInputDevice) {
                audioConstraint = {
                    deviceId: preferredAudioInputDevice
                };
            }
            else if (preferredAudioInputDeviceVolume) {
                audioConstraint = {
                    volume: preferredAudioInputDeviceVolume
                };
            }
        }
        return audioConstraint;
    }
    getVideoConstraintWithPreferences() {
        const preferredVideoInputDevice = this.preferredVideoInputDevice$.getValue();
        return preferredVideoInputDevice ? { deviceId: preferredVideoInputDevice } : true;
    }
    setPreferredAudioInputDevice(deviceId) {
        this.preferredAudioInputDevice$.next(deviceId);
    }
    setPreferredAudioOutputDevice(deviceId) {
        this.preferredAudioOutputDevice$.next(deviceId);
    }
    setPreferredVideoInputDevice(deviceId) {
        this.preferredVideoInputDevice$.next(deviceId);
    }
    setPreferredAudioInputDeviceVolume(volume) {
        this.preferredAudioInputDeviceVolume$.next(volume);
    }
    resetPreferences() {
        this.preferredAudioInputDevice$.next(null);
        this.preferredAudioOutputDevice$.next(null);
        this.preferredVideoInputDevice$.next(null);
        this.preferredAudioInputDeviceVolume$.next(null);
    }
}
PreferencesService.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: PreferencesService, deps: [{ token: Configuration }, { token: NGX_WEBRTC_STORAGE_PREFIX }, { token: NGX_WEBRTC_STORAGE }], target: i0.ɵɵFactoryTarget.Injectable });
PreferencesService.ɵprov = i0.ɵɵngDeclareInjectable({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: PreferencesService, providedIn: 'root' });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: PreferencesService, decorators: [{
            type: Injectable,
            args: [{
                    providedIn: 'root'
                }]
        }], ctorParameters: function () { return [{ type: Configuration }, { type: undefined, decorators: [{
                    type: Inject,
                    args: [NGX_WEBRTC_STORAGE_PREFIX]
                }] }, { type: undefined, decorators: [{
                    type: Inject,
                    args: [NGX_WEBRTC_STORAGE]
                }] }]; } });

class StreamService {
    constructor(config, preferencesService) {
        this.config = config;
        this.preferencesService = preferencesService;
        /**
         * You can subscribe to localSteam changes
         */
        this.localStream$ = new BehaviorSubject(null);
        /**
         * You can subscribe to screen share changes
         */
        this.localShareScreenStream$ = new BehaviorSubject(null);
        /**
         * Emitted with new Track when `StreamService.replaceTrack` is called
         */
        this.replaceTrack$ = new BehaviorSubject(null);
        /**
         * Emitted when `StreamService.setAudioOutput` is called with new device (Call it when the switch the audio device).
         */
        this.audioOutput$ = new BehaviorSubject(null);
        /**
         * Emitted when the status of the local stream changed e.g. audio or video disabled or enabled.
         */
        this.localStreamStatusChanged = new EventEmitter();
        /**
         * Emitted when the status of the local audio stream changed e.g. audio disabled or enabled.
         */
        this.localAudioStreamStatusChanged = new EventEmitter();
        /**
         * Emitted when the status of the local video stream changed e.g. video disabled or enabled.
         */
        this.localVideoStreamStatusChanged = new EventEmitter();
        /**
         * Set to `true` when the StreamService.tryGetUserMedia is succefull for video (camera).
         * @deprecated
         */
        this.hasVideo = false;
        /**
         * Set to `true` when the StreamService.tryGetUserMedia is succefull for audio (microphone).
         * @deprecated
         */
        this.hasAudio = false;
    }
    /**
     * Get aspect ratio for given width and height.
     * @param width width in pixel
     * @param height height in pixel
     * @returns aspect ratio for the given width and height
     */
    static getAspectRatio(width, height) {
        function gcd(a, b) {
            return b ? gcd(b, a % b) : a;
        }
        const divisor = gcd(width, height);
        return `${width / divisor}x${height / divisor}`;
    }
    /**
     *
     * @param node `HTMLVideoElement` or `HTMLAudioElement` that should play the stream.
     * @param stream stream to set in node
     * @param muted mute audio
     * @param local if set to `true` `localStreamStatusChanged` is emitted on play
     */
    setStreamInNode(node, stream, muted = true, local = false) {
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        const self = this;
        if (node) {
            // play when ready
            node.addEventListener('canplay', function onCanPlay(event) {
                // it doesn't matter if we use audio or video element here
                const eventTargetNode = event.target;
                if (eventTargetNode) {
                    eventTargetNode.removeEventListener('canplay', onCanPlay);
                    eventTargetNode.play();
                }
                if (local) {
                    self.localStreamStatusChanged.emit(stream);
                }
            });
            let tmpStream;
            if (stream instanceof MediaStreamTrack) {
                tmpStream = new MediaStream();
                tmpStream.addTrack(stream);
            }
            else {
                tmpStream = stream;
            }
            node.srcObject = tmpStream;
            node.muted = muted;
        }
    }
    /**
     * stop stream playing in node
     * @param node node with nativeElement type `HTMLVideoElement` or  `HTMLAudioElement`
     */
    stopStreamInNode(node) {
        node?.nativeElement?.pause();
        node?.nativeElement?.srcObject?.getTracks().forEach((t) => t.stop());
        if (node?.nativeElement?.srcObject) {
            node.nativeElement.srcObject = new MediaStream();
        }
    }
    toggleLocalTrack(type) {
        if (this.config.debug) {
            console.log('toggleLocalTrack()', type);
        }
        const stream = this.getLocalStream();
        if (stream) {
            const tracks = type === StreamType.Audio ? stream.getAudioTracks() : stream.getVideoTracks();
            if (tracks.length) {
                return this.disableLocalTrack(type);
            }
            else {
                return this.enableLocalTrack(type);
            }
        }
        else {
            return Promise.reject(new Error('no stream'));
        }
    }
    enableLocalTrack(type) {
        if (this.config.debug) {
            console.log('enableLocalTrack()', type);
        }
        return new Promise((resolve, rejects) => {
            const stream = this.getLocalStream();
            if (stream) {
                if (type === StreamType.Video) {
                    navigator.mediaDevices.getUserMedia({
                        video: this.preferencesService.getVideoConstraintWithPreferences(),
                    }).then(stream => {
                        const localStream = this.localStream$.getValue() || new MediaStream();
                        stream.getVideoTracks().forEach(track => {
                            localStream.addTrack(track);
                            this.localVideoStreamStatusChanged.emit(true);
                            this.replaceTrack(track);
                        });
                        this.localStream$.next(localStream);
                        this.localStreamStatusChanged.emit(localStream);
                        resolve(localStream);
                    }, (error) => {
                        rejects(error);
                    });
                }
                if (type === StreamType.Audio) {
                    navigator.mediaDevices.getUserMedia({
                        audio: this.preferencesService.getAudioConstraintWithPreferences(),
                    }).then(stream => {
                        const localStream = this.localStream$.getValue() || new MediaStream();
                        stream.getAudioTracks().forEach(track => {
                            localStream.addTrack(track);
                            this.localAudioStreamStatusChanged.emit(true);
                            this.replaceTrack(track);
                        });
                        this.localStream$.next(localStream);
                        this.localStreamStatusChanged.emit(localStream);
                        resolve(localStream);
                    }, (error) => {
                        rejects(error);
                    });
                }
            }
            else {
                rejects(new Error('no stream'));
            }
        });
    }
    disableLocalTrack(type) {
        if (this.config.debug) {
            console.log('disableLocalTrack()', type);
        }
        return new Promise((resolve, rejects) => {
            const stream = this.getLocalStream();
            if (stream) {
                const tracks = type === StreamType.Audio ? stream.getAudioTracks() : stream.getVideoTracks();
                tracks.forEach(track => {
                    track.enabled = false;
                    track.stop();
                    stream.removeTrack(track);
                });
                if (type === StreamType.Video) {
                    this.localVideoStreamStatusChanged.emit(false);
                }
                else {
                    this.localAudioStreamStatusChanged.emit(false);
                }
                this.localStreamStatusChanged.emit(stream);
                this.localStream$.next(stream);
                return resolve(stream);
            }
            else {
                rejects(new Error('no stream'));
            }
        });
    }
    /**
     * set stream or track mute state or toggle mute
     * @param stream stream or track
     * @param type stream or track type
     * @param value enforce `true` or `false`
     */
    toggleMuteStream(stream, type, value) {
        if (this.config.debug) {
            console.log('toggleMuteStream()', stream, type, value);
        }
        if (stream) {
            if (stream instanceof MediaStreamTrack) {
                const targetValue = typeof value !== 'undefined' ? value : !stream.enabled;
                stream.enabled = targetValue;
            }
            else {
                if (type === StreamType.Audio) {
                    stream.getAudioTracks().forEach(track => {
                        const targetValue = typeof value !== 'undefined' ? value : !track.enabled;
                        track.enabled = targetValue;
                        this.localAudioStreamStatusChanged.emit(targetValue);
                    });
                }
                if (type === StreamType.Video) {
                    stream.getVideoTracks().forEach(track => {
                        const targetValue = typeof value !== 'undefined' ? value : !track.enabled;
                        track.enabled = targetValue;
                        this.localVideoStreamStatusChanged.emit(targetValue);
                    });
                }
            }
        }
        this.localStreamStatusChanged.emit(stream);
    }
    /**
     * Mute stream in node.
     * @param stream stram or track
     * @param type stream or track type
     */
    muteStream(stream, type) {
        this.toggleMuteStream(stream, type, false);
    }
    /**
     * Unmute stream in node.
     * @param stream stram or track
     * @param type stream or track type
     */
    unmuteStream(stream, type) {
        this.toggleMuteStream(stream, type, true);
    }
    /**
     * replace a track in stream
     * @param stream stream with thre track to replace
     * @param track new track
     */
    replaceTrackInStream(stream, track) {
        if (track.kind === StreamType.Video) {
            stream?.getVideoTracks().forEach(e => {
                e.stop();
                stream.removeTrack(e);
            });
        }
        if (track.kind === StreamType.Audio) {
            stream?.getAudioTracks().forEach((e) => {
                e.stop();
                stream.removeTrack(e);
            });
        }
        stream?.addTrack(track);
    }
    /**
     * set local stream in service state
     * @param stream stream to set
     */
    setLocalStream(stream) {
        this.localStream$.next(stream);
    }
    /**
     * get current state value of local stream
     * @returns current local stream
     */
    getLocalStream() {
        return this.localStream$.getValue();
    }
    /**
     * set replace track service state. You can subscribe to `StreamService.replaceTrack$` to update the track somewhere.
     * @param track new track
     */
    replaceTrack(track) {
        this.replaceTrack$.next(track);
    }
    /**
     * toggle mute audio of local stream
     */
    toggleMuteLocalAudioStream() {
        const stream = this.localStream$.getValue();
        if (stream) {
            this.toggleMuteStream(stream, StreamType.Audio);
        }
    }
    /**
     * mute local audio stream
     */
    muteLocalAudioStream() {
        const stream = this.localStream$.getValue();
        if (stream) {
            this.toggleMuteStream(stream, StreamType.Audio, false);
        }
    }
    /**
     * unmute local audio stream
     */
    unmuteLocalAudioStream() {
        const stream = this.localStream$.getValue();
        if (stream) {
            this.toggleMuteStream(stream, StreamType.Audio, true);
        }
    }
    /**
     * toggle mute local video stream
     */
    toggleMuteLocalVideoStream() {
        const stream = this.localStream$.getValue();
        if (stream) {
            this.toggleMuteStream(stream, StreamType.Video);
        }
    }
    /**
     * mute local video stream
     */
    muteLocalVideoStream() {
        const stream = this.localStream$.getValue();
        if (stream) {
            this.toggleMuteStream(stream, StreamType.Video, false);
        }
    }
    /**
     * unmute local video stream
     */
    unmuteLocalVideoStream() {
        const value = this.localStream$.getValue();
        if (value) {
            this.toggleMuteStream(value, StreamType.Video, true);
        }
    }
    /**
     * get screen or window as stream
     * @returns MediaStram of desktop or display
     */
    async getScreenCapture() {
        let stream = null;
        try {
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            const n = navigator;
            if (n.getDisplayMedia) {
                stream = await n.getDisplayMedia({ video: true });
            }
            else if (n.mediaDevices.getDisplayMedia) {
                stream = await n.mediaDevices.getDisplayMedia({ video: true });
            }
            else {
                stream = await n.mediaDevices.getUserMedia({ video: { mediaSource: 'screen' } });
            }
        }
        catch (e) {
            if (this.config.debug) {
                console.log(`MdoVideoCallComponent.getScreenCapture() -> no permissions`);
            }
        }
        return stream;
    }
    /**
     * get first/single video track of the given stream
     * @param stream stream with video treack
     * @returns first video track of stream
     */
    getVideoTrackForStream(stream) {
        if (!stream && this.getLocalStream()) {
            stream = this.getLocalStream();
        }
        return stream?.getVideoTracks()[0] || null;
    }
    /**
     * get first/single audio track of the given stream
     * @param stream stream with audio treack
     * @returns first audio track of stream
     */
    getAudioTrackForStream(stream) {
        if (!stream && this.getLocalStream()) {
            stream = this.getLocalStream();
        }
        return stream?.getAudioTracks()[0] || null;
    }
    /**
     * get media devices, Attention you need getMedia permissions for this call
     * @returns Promise that resolves to media Devices as array
     * @deprecated use DeviceService.getMediaDevices() instead
     */
    getMediaDevices() {
        return navigator.mediaDevices.enumerateDevices();
    }
    /**
     * set current audio device in service state. You can subscribe to `StreamService.audioOutput$` to get changes.
     * @param deviceId
     */
    setAudioOutput(deviceId) {
        this.audioOutput$.next(deviceId);
    }
    // TODO: refactor
    /**
     * An simple wrapper for `navigator.mediaDevices.getUserMedia`, with basis error handling.
     * @todo refactor
     * @param mediaConstraints a MediaStreamConstraints e.g. with specific deviceId, resolution or just audio. Default is:
     *                          ```json
     *                         {
     *                             audio: true,
     *                             video: true
     *                         }
     *                         ```
     * @returns Promise that resilve to a stream matching the constraint
     * @deprecated use DeviceService.tryGetUserMedia() instead
     */
    tryGetUserMedia(mediaConstraints) {
        // reset state
        this.hasAudio = false;
        this.hasVideo = false;
        if (!mediaConstraints) {
            mediaConstraints = {
                audio: true,
                video: true
            };
        }
        ;
        return new Promise((resolve, reject) => {
            navigator.mediaDevices.getUserMedia(mediaConstraints).then(a => {
                this.hasAudio = true;
                this.hasVideo = true;
                resolve(a);
            }, b => {
                let cam = true, mic = true;
                if (b.message.indexOf('Starting videoinput failed') > -1) {
                    if (this.config.debug) {
                        console.log('videoinput used by another software');
                    }
                    cam = false;
                }
                navigator.mediaDevices.enumerateDevices().then((devices) => {
                    cam = cam && devices.find((device) => {
                        return device.kind === 'videoinput';
                    }) !== null;
                    mic = devices.find((device) => {
                        return device.kind === 'audioinput';
                    }) !== null;
                    const constraints = {
                        video: cam && mediaConstraints?.video,
                        audio: mic && mediaConstraints?.audio
                    };
                    navigator.mediaDevices.getUserMedia(constraints).then(a => {
                        this.hasAudio = true;
                        resolve(a);
                    }, reject);
                }, (f) => {
                    reject(f);
                });
            }).catch(e => {
                reject(e);
            });
        });
    }
}
StreamService.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: StreamService, deps: [{ token: Configuration }, { token: PreferencesService }], target: i0.ɵɵFactoryTarget.Injectable });
StreamService.ɵprov = i0.ɵɵngDeclareInjectable({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: StreamService, providedIn: 'root' });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: StreamService, decorators: [{
            type: Injectable,
            args: [{
                    providedIn: 'root'
                }]
        }], ctorParameters: function () { return [{ type: Configuration }, { type: PreferencesService }]; } });

/**
 * Toggle disabled/enable video track to mute/unmute local video.
 */
class ToggleVideoSelfDirective {
    constructor(streamService, callService, cdr) {
        this.streamService = streamService;
        this.callService = callService;
        this.cdr = cdr;
        this.callStartedSubscription$ = null;
        this.localStreamStatusChangedSubscription$ = null;
        this.toggleMuteFailed = new EventEmitter();
        this.isDisabled = true;
        this.isEnabled = false;
        this.init();
    }
    onClick() {
        this.toggleMute();
    }
    ngOnDestroy() {
        this.callStartedSubscription$?.unsubscribe();
        this.localStreamStatusChangedSubscription$?.unsubscribe();
    }
    init() {
        this.callStartedSubscription$ = this.callService.started$.subscribe(this.onStart.bind(this));
    }
    onStart(isStarted) {
        if (isStarted) {
            this.localStreamStatusChangedSubscription$ = this.streamService.localStreamStatusChanged.subscribe(this.onLocalStreamStatusChanged.bind(this));
        }
    }
    onLocalStreamStatusChanged(stream) {
        if (stream) {
            if (stream instanceof MediaStreamTrack && stream.kind === StreamType.Video) {
                this.updateStatusWithTrack(stream);
            }
            if (stream instanceof MediaStream) {
                const track = this.streamService.getVideoTrackForStream(stream);
                this.updateStatusWithTrack(track);
            }
        }
    }
    toggleMute() {
        this.streamService.toggleLocalTrack(StreamType.Video).catch(error => {
            this.toggleMuteFailed.emit(error);
        });
    }
    updateStatusWithTrack(track) {
        this.isEnabled = track && track.enabled ? true : false;
        this.isDisabled = !track || !track.enabled;
        this.cdr.detectChanges();
    }
}
ToggleVideoSelfDirective.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ToggleVideoSelfDirective, deps: [{ token: StreamService }, { token: CallService }, { token: i0.ChangeDetectorRef }], target: i0.ɵɵFactoryTarget.Directive });
ToggleVideoSelfDirective.ɵdir = i0.ɵɵngDeclareDirective({ minVersion: "12.0.0", version: "13.2.1", type: ToggleVideoSelfDirective, selector: "[ngxWebrtcToggleVideoSelf]", outputs: { toggleMuteFailed: "toggleMuteFailed" }, host: { listeners: { "click": "onClick($event)" }, properties: { "class.disabled": "this.isDisabled", "class.enabled": "this.isEnabled" } }, ngImport: i0 });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ToggleVideoSelfDirective, decorators: [{
            type: Directive,
            args: [{
                    selector: '[ngxWebrtcToggleVideoSelf]',
                }]
        }], ctorParameters: function () { return [{ type: StreamService }, { type: CallService }, { type: i0.ChangeDetectorRef }]; }, propDecorators: { toggleMuteFailed: [{
                type: Output
            }], isDisabled: [{
                type: HostBinding,
                args: ['class.disabled']
            }], isEnabled: [{
                type: HostBinding,
                args: ['class.enabled']
            }], onClick: [{
                type: HostListener,
                args: ['click', ['$event']]
            }] } });

/**
 * Trigger get capture screen permissions and send screen to CallService.
 * You can listen to the change and call replaceTrack of peer connection to send the screen capture to that connection
 */
class ShareScreenDirective {
    constructor(streamService, callService, cdr) {
        this.streamService = streamService;
        this.callService = callService;
        this.cdr = cdr;
        this.desktopStream = null;
        this.isDisabled = true;
        this.isEnabled = false;
    }
    async onClick() {
        if (!this.isEnabled) {
            await this.startShareScreen();
        }
        else {
            this.stopShareScreen();
        }
    }
    async startShareScreen() {
        this.desktopStream = await this.streamService.getScreenCapture();
        if (this.desktopStream) {
            this.streamService.localShareScreenStream$.next(this.desktopStream);
            const desktopVideoTrack = this.streamService.getVideoTrackForStream(this.desktopStream);
            if (desktopVideoTrack) {
                this.streamService.replaceTrack(desktopVideoTrack);
            }
            else {
                console.warn('no videotrack in desktop stream');
            }
            const streamInactive$ = fromEvent(this.desktopStream, 'inactive').pipe(take(1));
            const sharingStopped$ = fromEvent(this.desktopStream.getVideoTracks()[0], 'ended').pipe(take(1));
            merge(streamInactive$, sharingStopped$)
                .pipe(take(1))
                .subscribe(() => {
                if (this.isEnabled) {
                    this.stopShareScreen();
                }
            });
            this.isEnabled = !this.isEnabled;
            this.isDisabled = !this.isDisabled;
            this.callService.startShareScreen.emit();
            this.cdr.detectChanges();
        }
    }
    stopShareScreen() {
        this.streamService.localShareScreenStream$.next(null);
        const videoTrack = this.streamService.getVideoTrackForStream();
        if (videoTrack) {
            this.streamService.replaceTrack(videoTrack);
        }
        else {
            console.warn('video track not found');
        }
        if (this.desktopStream) {
            this.desktopStream.getTracks().forEach(track => {
                track.stop();
            });
        }
        this.callService.stopShareScreen.emit();
        this.isEnabled = !this.isEnabled;
        this.isDisabled = !this.isDisabled;
        this.cdr.detectChanges();
    }
}
ShareScreenDirective.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ShareScreenDirective, deps: [{ token: StreamService }, { token: CallService }, { token: i0.ChangeDetectorRef }], target: i0.ɵɵFactoryTarget.Directive });
ShareScreenDirective.ɵdir = i0.ɵɵngDeclareDirective({ minVersion: "12.0.0", version: "13.2.1", type: ShareScreenDirective, selector: "[ngxWebrtcShareScreen]", host: { listeners: { "click": "onClick($event)" }, properties: { "class.disabled": "this.isDisabled", "class.enabled": "this.isEnabled" } }, ngImport: i0 });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ShareScreenDirective, decorators: [{
            type: Directive,
            args: [{
                    selector: '[ngxWebrtcShareScreen]',
                }]
        }], ctorParameters: function () { return [{ type: StreamService }, { type: CallService }, { type: i0.ChangeDetectorRef }]; }, propDecorators: { isDisabled: [{
                type: HostBinding,
                args: ['class.disabled']
            }], isEnabled: [{
                type: HostBinding,
                args: ['class.enabled']
            }], onClick: [{
                type: HostListener,
                args: ['click', ['$event']]
            }] } });

/**
 * Toggle disabled/enable audio track to mute/unmute local audio.
 */
class ToggleAudioSelfDirective {
    constructor(streamService, callService, cdr) {
        this.streamService = streamService;
        this.callService = callService;
        this.cdr = cdr;
        this.callStartedSubscription$ = null;
        this.localStreamStatusChangedSubscription$ = null;
        this.toggleMuteFailed = new EventEmitter();
        this.isDisabled = true;
        this.isEnabled = false;
        this.init();
    }
    onClick() {
        this.toggleMute();
    }
    ngOnDestroy() {
        this.callStartedSubscription$?.unsubscribe();
        this.localStreamStatusChangedSubscription$?.unsubscribe();
    }
    init() {
        this.callStartedSubscription$ = this.callService.started$.subscribe(this.onStart.bind(this));
    }
    onStart(isStarted) {
        if (isStarted) {
            this.localStreamStatusChangedSubscription$ = this.streamService.localStreamStatusChanged.subscribe(this.onLocalStreamStatusChanged.bind(this));
        }
    }
    onLocalStreamStatusChanged(stream) {
        if (stream) {
            if (stream instanceof MediaStreamTrack && stream.kind === StreamType.Audio) {
                this.updateStatusWithTrack(stream);
            }
            if (stream instanceof MediaStream) {
                const track = this.streamService.getAudioTrackForStream(stream);
                this.updateStatusWithTrack(track);
            }
        }
    }
    toggleMute() {
        this.streamService.toggleLocalTrack(StreamType.Audio).catch(error => {
            this.toggleMuteFailed.emit(error);
        });
    }
    updateStatusWithTrack(track) {
        this.isEnabled = track && track.enabled ? true : false;
        this.isDisabled = !track || !track.enabled;
        this.cdr.detectChanges();
    }
}
ToggleAudioSelfDirective.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ToggleAudioSelfDirective, deps: [{ token: StreamService }, { token: CallService }, { token: i0.ChangeDetectorRef }], target: i0.ɵɵFactoryTarget.Directive });
ToggleAudioSelfDirective.ɵdir = i0.ɵɵngDeclareDirective({ minVersion: "12.0.0", version: "13.2.1", type: ToggleAudioSelfDirective, selector: "[ngxWebrtcToggleAudioSelf]", outputs: { toggleMuteFailed: "toggleMuteFailed" }, host: { listeners: { "click": "onClick($event)" }, properties: { "class.disabled": "this.isDisabled", "class.enabled": "this.isEnabled" } }, ngImport: i0 });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: ToggleAudioSelfDirective, decorators: [{
            type: Directive,
            args: [{
                    selector: '[ngxWebrtcToggleAudioSelf]',
                }]
        }], ctorParameters: function () { return [{ type: StreamService }, { type: CallService }, { type: i0.ChangeDetectorRef }]; }, propDecorators: { toggleMuteFailed: [{
                type: Output
            }], isDisabled: [{
                type: HostBinding,
                args: ['class.disabled']
            }], isEnabled: [{
                type: HostBinding,
                args: ['class.enabled']
            }], onClick: [{
                type: HostListener,
                args: ['click', ['$event']]
            }] } });

class NgxWebrtcModule {
    static forRoot(libConfiguration) {
        return {
            ngModule: NgxWebrtcModule,
            providers: [
                {
                    provide: Configuration,
                    useValue: libConfiguration,
                },
            ],
        };
    }
}
NgxWebrtcModule.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: NgxWebrtcModule, deps: [], target: i0.ɵɵFactoryTarget.NgModule });
NgxWebrtcModule.ɵmod = i0.ɵɵngDeclareNgModule({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: NgxWebrtcModule, declarations: [ToggleAudioSelfDirective,
        ToggleVideoSelfDirective,
        ToggleAudioUserDirective,
        ToggleVideoUserDirective,
        ShareScreenDirective], imports: [CommonModule], exports: [ToggleAudioSelfDirective,
        ToggleVideoSelfDirective,
        ToggleAudioUserDirective,
        ToggleVideoUserDirective,
        ShareScreenDirective] });
NgxWebrtcModule.ɵinj = i0.ɵɵngDeclareInjector({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: NgxWebrtcModule, providers: [
        { provide: NGX_WEBRTC_STORAGE_PREFIX, useValue: 'ngx-webrtc' },
        { provide: NGX_WEBRTC_STORAGE, useValue: 'sessionStorage' },
    ], imports: [[CommonModule]] });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: NgxWebrtcModule, decorators: [{
            type: NgModule,
            args: [{
                    declarations: [
                        ToggleAudioSelfDirective,
                        ToggleVideoSelfDirective,
                        ToggleAudioUserDirective,
                        ToggleVideoUserDirective,
                        ShareScreenDirective,
                    ],
                    exports: [
                        ToggleAudioSelfDirective,
                        ToggleVideoSelfDirective,
                        ToggleAudioUserDirective,
                        ToggleVideoUserDirective,
                        ShareScreenDirective,
                    ],
                    imports: [CommonModule],
                    providers: [
                        { provide: NGX_WEBRTC_STORAGE_PREFIX, useValue: 'ngx-webrtc' },
                        { provide: NGX_WEBRTC_STORAGE, useValue: 'sessionStorage' },
                    ]
                }]
        }] });

// like MediaDeviceKind
var DeviceType;
(function (DeviceType) {
    DeviceType["AudioInput"] = "audioinput";
    DeviceType["AudioOutput"] = "audiooutput";
    DeviceType["VideoInput"] = "videoinput";
})(DeviceType || (DeviceType = {}));

/**
 * The DeviceService help you with device interaction (audio and video devices) and can hold a state for devices if you want to implement
 * a lobby with device testing.
 */
class DeviceService {
    constructor(config, streamService, preferencesService) {
        this.config = config;
        this.streamService = streamService;
        this.preferencesService = preferencesService;
        this.storage = 'sessionStorage';
        this.selectedAudioInput$ = new BehaviorSubject(null);
        this.selectedVideoInput$ = new BehaviorSubject(null);
        this.devices$ = new BehaviorSubject([]);
        this.devicesGoups$ = new BehaviorSubject([]);
        this.onDeviceChangeListener = () => {
            this.detectSelectedDevices().then(devices => {
                if (this.config.debug) {
                    console.log('devices after devicechange event');
                    console.log(devices);
                }
            });
        };
        // not possible with HostListener
        navigator.mediaDevices.addEventListener('devicechange', this.onDeviceChangeListener);
    }
    ngOnDestroy() {
        navigator.mediaDevices.removeEventListener('devicechange', this.onDeviceChangeListener);
    }
    detectSelectedDevices() {
        return new Promise((resolve, reject) => {
            this.getMediaDevices().then(devices => {
                this.devices$.next(devices);
                this.devicesGoups$.next(this.groupDeviceByKind(devices, []));
                resolve(devices);
            }, reject);
        });
    }
    getMediaDevicesGrouped(omit = []) {
        const devicesGoups = this.devicesGoups$.getValue();
        if (omit.length) {
            return devicesGoups.filter(e => !omit.includes(e.kind));
        }
        return devicesGoups;
    }
    /**
     * get media devices, Attention you need getMedia permissions for this call
     * @returns Promise that resolves to media Devices as array
     */
    getMediaDevices() {
        return navigator.mediaDevices.enumerateDevices();
    }
    /**
     * Change selected device wit a deviceId and a device type.
     * @param deviceId id of selected device
     * @param kind type of selected device `VideDevice` or `AudioDevice`
     */
    changeSelectedDevice(deviceId, kind) {
        return new Promise((resolve, rejects) => {
            const devices = this.devices$.getValue();
            if (kind === DeviceType.VideoInput) {
                if (this.selectedVideoInput$.getValue()?.deviceId === deviceId) {
                    resolve();
                }
                navigator.mediaDevices.getUserMedia({ video: {
                        deviceId
                    } }).then((newStream) => {
                    this.preferencesService.setPreferredVideoInputDevice(deviceId);
                    if (devices && devices.length) {
                        const device = devices.find(d => d.deviceId === deviceId);
                        if (device) {
                            this.selectedVideoInput$.next(device);
                        }
                    }
                    const track = this.streamService.getVideoTrackForStream(newStream);
                    const currentStream = this.streamService.getLocalStream();
                    if (currentStream && track) {
                        this.streamService.replaceTrack(track);
                        const oldTrack = this.streamService.getVideoTrackForStream(currentStream);
                        oldTrack?.stop();
                        this.streamService.replaceTrackInStream(currentStream, track);
                    }
                    else {
                        this.streamService.setLocalStream(newStream);
                    }
                    resolve();
                }, (error) => {
                    console.error(error);
                    rejects(error);
                });
            }
            if (kind === DeviceType.AudioInput) {
                if (this.selectedAudioInput$.getValue()?.deviceId === deviceId) {
                    resolve();
                }
                navigator.mediaDevices.getUserMedia({ audio: {
                        deviceId
                    } }).then((newStream) => {
                    this.preferencesService.setPreferredAudioInputDevice(deviceId);
                    if (devices && devices.length) {
                        const device = devices.find(d => d.deviceId === deviceId);
                        if (device) {
                            this.selectedAudioInput$.next(device);
                        }
                    }
                    const track = this.streamService.getAudioTrackForStream(newStream);
                    if (track) {
                        this.streamService.replaceTrack(track);
                    }
                    const currentStream = this.streamService.getLocalStream();
                    if (currentStream && track) {
                        const oldTrack = this.streamService.getAudioTrackForStream(currentStream);
                        oldTrack?.stop();
                        this.streamService.replaceTrackInStream(currentStream, track);
                    }
                    else {
                        this.streamService.setLocalStream(newStream);
                    }
                    resolve();
                }, (error) => {
                    console.error(error);
                    rejects(error);
                });
            }
            if (kind === DeviceType.AudioOutput) {
                this.streamService.setAudioOutput(deviceId);
                resolve();
            }
        });
    }
    /**
     * Check the given device, if it's selected.
     * @param device device to check if it's selected
     * @param kind the kind of the device to check
     * @returns `true` if the devie is selected, outerwise `false`
     */
    isDeviceSelected(device, kind) {
        const stream = this.streamService.getLocalStream();
        if (stream) {
            if (kind === DeviceType.VideoInput && this.streamService.hasVideo) {
                const track = this.streamService.getVideoTrackForStream(stream);
                if (track) {
                    return track.getSettings().deviceId === device.deviceId;
                }
            }
            if (kind === DeviceType.AudioInput && this.streamService.hasAudio) {
                const track = this.streamService.getAudioTrackForStream(stream);
                if (track) {
                    return track.getSettings().deviceId === device.deviceId;
                }
            }
        }
        return false;
    }
    /**
     * group a list of devices you get by calling `StreamService.getMediaDevices()` by type.
     * @param devices list of devices you get by calling `StreamService.getMediaDevices()`
     * @returns a list of devices grouped by `DeviceType`
     */
    groupDeviceByKind(devices, omit = []) {
        const devicesGoups = [];
        const audioInput = devices.filter(d => d.kind === DeviceType.AudioInput);
        const audioOutput = devices.filter(d => d.kind === DeviceType.AudioOutput);
        const videoinput = devices.filter(d => d.kind === DeviceType.VideoInput);
        if (audioInput.length && !omit.includes(DeviceType.AudioInput)) {
            devicesGoups.push({
                kind: DeviceType.AudioInput,
                devices: audioInput
            });
        }
        if (audioOutput.length && !omit.includes(DeviceType.AudioOutput)) {
            devicesGoups.push({
                kind: DeviceType.AudioOutput,
                devices: audioOutput
            });
        }
        if (videoinput.length && !omit.includes(DeviceType.VideoInput)) {
            devicesGoups.push({
                kind: DeviceType.VideoInput,
                devices: videoinput
            });
        }
        return devicesGoups;
    }
    /**
     * An simple wrapper for `navigator.mediaDevices.getUserMedia`, with basis error handling.
     * @todo refactor
     * @param mediaConstraints a MediaStreamConstraints e.g. with specific deviceId, resolution or just audio. Default is:
     *                          ```json
     *                         {
     *                             audio: true,
     *                             video: true
     *                         }
     *                         ```
     * @returns Promise that resilve to a stream matching the constraint
     */
    tryGetUserMedia(mediaConstraints) {
        if (!mediaConstraints) {
            mediaConstraints = {
                audio: true,
                video: true
            };
        }
        ;
        return new Promise((resolve, reject) => {
            this.detectSelectedDevices().then(() => {
                navigator.mediaDevices.getUserMedia(mediaConstraints).then(steam => {
                    this.setDeviceAndResolve(steam, resolve);
                }, reject);
            }, reject);
        });
    }
    findFirstSuccessful(promises, onSuccess, onNotFound) {
        const currentPromise = promises.shift();
        if (currentPromise) {
            currentPromise().then(onSuccess, () => {
                this.findFirstSuccessful(promises, onSuccess, onNotFound);
            });
        }
        else {
            onNotFound();
        }
    }
    tryGetMedia(onSuccess, onNotFound) {
        const tryChain = [
            this.tryGetMediaWithPreferences.bind(this),
            this.tryGetMediaDefault.bind(this),
            this.tryGetMediaAudioOnly.bind(this)
        ];
        this.findFirstSuccessful(tryChain, onSuccess, onNotFound);
    }
    tryGetMediaWithPreferences() {
        const preferencesConstrains = {
            video: this.preferencesService.getVideoConstraintWithPreferences(),
            audio: this.preferencesService.getAudioConstraintWithPreferences(),
        };
        return this.tryGetUserMedia(preferencesConstrains);
    }
    tryGetMediaDefault() {
        this.preferencesService.resetPreferences();
        return this.tryGetUserMedia({
            video: true,
            audio: true
        });
    }
    tryGetMediaAudioOnly() {
        return this.tryGetUserMedia({
            video: false,
            audio: true
        });
    }
    setDeviceAndResolve(stream, resolve) {
        const devicesGoups = this.devicesGoups$.getValue();
        const videoDevices = devicesGoups.find(e => e.kind === DeviceType.VideoInput);
        const videoTrack = this.streamService.getVideoTrackForStream(stream);
        if (videoTrack && videoDevices) {
            const selectedVideoDevice = videoDevices.devices.find(e => e.deviceId === videoTrack.getSettings().deviceId);
            if (selectedVideoDevice) {
                this.selectedVideoInput$.next(selectedVideoDevice);
                this.preferencesService.setPreferredVideoInputDevice(selectedVideoDevice.deviceId);
            }
        }
        const audioDevices = devicesGoups.find(e => e.kind === DeviceType.AudioInput);
        const audioTrack = this.streamService.getAudioTrackForStream(stream);
        if (audioTrack && audioDevices) {
            const selectedAudioDevice = audioDevices.devices.find(e => e.deviceId === audioTrack.getSettings().deviceId);
            if (selectedAudioDevice) {
                this.selectedAudioInput$.next(selectedAudioDevice);
                this.preferencesService.setPreferredAudioInputDevice(selectedAudioDevice.deviceId);
            }
        }
        resolve(stream);
    }
}
DeviceService.ɵfac = i0.ɵɵngDeclareFactory({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: DeviceService, deps: [{ token: Configuration }, { token: StreamService }, { token: PreferencesService }], target: i0.ɵɵFactoryTarget.Injectable });
DeviceService.ɵprov = i0.ɵɵngDeclareInjectable({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: DeviceService, providedIn: 'root' });
i0.ɵɵngDeclareClassMetadata({ minVersion: "12.0.0", version: "13.2.1", ngImport: i0, type: DeviceService, decorators: [{
            type: Injectable,
            args: [{
                    providedIn: 'root'
                }]
        }], ctorParameters: function () { return [{ type: Configuration }, { type: StreamService }, { type: PreferencesService }]; } });

/**
 * Generated bundle index. Do not edit.
 */

export { CallService, Configuration, DeviceService, DeviceType, NGX_WEBRTC_STORAGE, NGX_WEBRTC_STORAGE_PREFIX, NgxWebrtcModule, PeerConnectionClient, PeerConnectionClientSignalMessageType, PreferencesService, SdpUtils, ShareScreenDirective, StreamService, StreamType, ToggleAudioSelfDirective, ToggleAudioUserDirective, ToggleVideoSelfDirective, ToggleVideoUserDirective, UtilityService };
//# sourceMappingURL=ngx-webrtc.mjs.map
